"""
Node implementations for the Customer Support Agent workflow.
Contains all the graph nodes including agent_node, tool_node, and their variants.
"""

import re
from typing import Literal
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage

from .state import AgentState
from .runnable import get_agent_runnable
from utils.logger import logger
from utils.streaming import stream_response2
from utils.response_extractor import extract_final_answer
from tools import get_all_tools, execute_tool



def parse_action_from_response(content: str) -> dict:
    """
    Parses content string from AIMessage into action data if present.
    
    Args:
        content: The content string from an AI message
        
    Returns:
        dict: Action information if found, None otherwise
    """
    action_match = re.search(r"Action:\s*(.+)", content)
    input_match = re.search(r"Action Input:\s*(.+)", content)
    
    if action_match and input_match:
        return {
            "action": action_match.group(1).strip(),
            "action_input": input_match.group(1).strip()
        }
    return None


def agent_node(state: AgentState) -> AgentState:
    """
    Standard agent node that processes user input and decides next action.
    
    Args:
        state: Current agent state
        
    Returns:
        Updated agent state with next action decision
    """
    agent_runnable = get_agent_runnable()
    response = agent_runnable.invoke(state)
    
    # Try to parse action info from response content
    action_info = parse_action_from_response(response.content)
    
    if action_info:
        logger.debug("\n--- AGENT DECIDED TO CALL A TOOL ---")
        return {
            "messages": [response],
            "next_action": "call_tool",
            "actions": [action_info]
        }
    else:
        logger.debug("\n--- AGENT DECIDED TO RESPOND DIRECTLY ---")
       # Extract clean final answer for display
        clean_answer = extract_final_answer(response.content)
        # Create a new AIMessage with just the clean answer
        clean_response = AIMessage(content=clean_answer, name="agent")
        return {
            "messages": [clean_response],
            "next_action": "respond"
        }


def agent_node_with_streaming(state: AgentState) -> AgentState:
    from .runnable import get_llm_with_tools, get_agent_prompt
    from .runnable import get_chat_history, get_current_input, get_agent_scratchpad

    tools = get_all_tools()
    llm_with_tools = get_llm_with_tools()
    agent_prompt = get_agent_prompt()

    # Build enhanced state
    enhanced_state = {
        "messages": state["messages"],
        "tools": tools,
        "tool_names": [t.name for t in tools],
        "input": get_current_input(state["messages"]),
        "chat_history": get_chat_history(state["messages"]),
        "agent_scratchpad": get_agent_scratchpad(state["messages"]),
    }

    # Format final prompt sent to LLM (ReAct)
    formatted_prompt = agent_prompt.invoke(enhanced_state)

    # ðŸš€ STREAM the final LLM response
    ai_message = stream_response2(llm_with_tools, formatted_prompt)

    # ðŸš¨ Detect tool call from streamed text (only 1 pass!)
    action_info = parse_action_from_response(ai_message.content)

    if action_info:
        logger.debug("--- AGENT DECIDED TO CALL A TOOL ---")
        return {
            "messages": [ai_message],
            "next_action": "call_tool",
            "actions": [action_info]
        }

    # Otherwise, final answer
    return {
        "messages": [ai_message],
        "next_action": "respond"
    }


def tool_node(state: AgentState) -> AgentState:
    """
    Tool execution node that processes tool calls and returns results.
    
    Args:
        state: Current agent state with tool actions to execute
        
    Returns:
        Updated agent state with tool outputs
    """
    
    messages = state["messages"]
    actions = state["actions"]
    last_message = messages[-1] if messages else None
    
    logger.debug("Processing tool calls: {}", actions)
    
    tool_outputs = []
    for action_info in actions:
        logger.debug("\n--- PROCESSING TOOL CALL: {} ---", action_info)
        
        if isinstance(action_info, dict):
            tool_name = action_info.get("action")
            tool_args = action_info.get("action_input")
        else:
            tool_name = getattr(action_info, "action", None)
            tool_args = getattr(action_info, "action_input", None)
            
        if not tool_name or not tool_args:
            logger.debug("ERROR: Malformed tool call item: {}", action_info)
            tool_outputs.append(
                ToolMessage(
                    content="Error: Malformed tool call received.", 
                    tool_call_id=str(tool_name) if tool_name else "unknown"
                )
            )
            continue
            
        # Execute the tool
        try:
            output = execute_tool(tool_name, tool_args)
            logger.debug("Output from {}: {}", tool_name, output)
            tool_outputs.append(
                ToolMessage(
                    content=output, 
                    tool_call_id=tool_name
                )
            )
        except Exception as e:
            logger.debug("Error executing tool {}: {}", tool_name, e)
            tool_outputs.append(
                ToolMessage(
                    content=f"Error: Failed to execute tool {tool_name}: {str(e)}", 
                    tool_call_id=tool_name
                )
            )
            
    return {
        "messages": tool_outputs, 
        "next_action": "respond"
    }


def decide_next_step(state: AgentState) -> Literal["tool_node", "respond_and_end"]:
    """
    Decision function to determine the next step in the workflow.
    
    Args:
        state: Current agent state
        
    Returns:
        Next node to execute in the workflow
    """
    if state["next_action"] == "call_tool":
        logger.debug("\n--- DECIDING NEXT STEP: CALL TOOL ---")
        return "tool_node"
    elif state["next_action"] == "respond":
        return "respond_and_end"
    else:
        return "respond_and_end"